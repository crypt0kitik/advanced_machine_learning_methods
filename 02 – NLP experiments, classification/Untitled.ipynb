{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4dd690ff-8b40-4211-a3d9-d5c9865d966b",
   "metadata": {},
   "source": [
    "The current code does not use a classifier; it directly calculates participants’ knowledge progression based on their pre-test and post-test scores. This approach is more of a rule-based classification rather than using machine learning.\n",
    "\n",
    "How It Works:\n",
    "\t•\tComputes the total score difference for each participant.\n",
    "\t•\tApplies a rule-based function to classify them into three groups:\n",
    "\t•\t\"Improved\" → If post-test score is higher than pre-test.\n",
    "\t•\t\"Declined\" → If post-test score is lower than pre-test.\n",
    "\t•\t\"Same Stage\" → If post-test score did not change.\n",
    "\n",
    "This is a deterministic approach based on numeric differences, not a machine learning classifier.\n",
    "\n",
    "\n",
    "YOU can keep only labels , make them numeric and based on this data , create clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c53e0f33-e4ce-4021-acb9-e98a7f866bae",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'arr_0 is not a file in the archive'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 50\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(file):\n\u001b[1;32m     49\u001b[0m     data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(file, allow_pickle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 50\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43marr_0\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m, columns\u001b[38;5;241m=\u001b[39mdata[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     51\u001b[0m     group_performance \u001b[38;5;241m=\u001b[39m analyze_group_performance(df)\n\u001b[1;32m     52\u001b[0m     group_performance[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m file\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/numpy/lib/npyio.py:260\u001b[0m, in \u001b[0;36mNpzFile.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mzip\u001b[38;5;241m.\u001b[39mread(key)\n\u001b[1;32m    259\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 260\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is not a file in the archive\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'arr_0 is not a file in the archive'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define survey files\n",
    "survey_files = [\n",
    "    \"01.1_df_word_token_stopwords_lemmatize_vectorized.npz\",\n",
    "    \"01.2_df_subword_token_stopwords_lemmatize_vectorized.npz\",\n",
    "    \"01.3_df_sentence_token_stopwords_lemmatize_vectorized.npz\",\n",
    "    \"01.4_df_bert_token_stopwords_lemmatize_vectorized.npz\",\n",
    "    \"01.5_df_tiktoken_token_stopwords_lemmatize_vectorized.npz\",\n",
    "    \"01.6_df_whitespace_token_stopwords_lemmatize_vectorized.npz\"\n",
    "]\n",
    "\n",
    "# List of relevant columns for grading\n",
    "columns_to_compare = [\n",
    "    \"persona_definition_pre_grade\", \"persona_definition_post_grade\",\n",
    "    \"interactive_persona_pre_grade\", \"interactive_persona_post_grade\",\n",
    "    \"data_driven_persona_pre_grade\", \"data_driven_persona_post_grade\",\n",
    "    \"dynamic_persona_pre_grade\", \"dynamic_persona_post_grade\"\n",
    "]\n",
    "\n",
    "def classify_progress(pre, post):\n",
    "    if pre == \"Correct\" and post == \"Not Correct\":\n",
    "        return \"DECLINED\"\n",
    "    elif pre == \"Not Correct\" and post == \"Correct\":\n",
    "        return \"IMPROVED\"\n",
    "    else:\n",
    "        return \"SAME\"\n",
    "\n",
    "def analyze_group_performance(df):\n",
    "    df[\"progress\"] = df.apply(lambda row: classify_progress(row[columns_to_compare[0]], row[columns_to_compare[1]]), axis=1)\n",
    "    for i in range(2, len(columns_to_compare), 2):\n",
    "        df[\"progress\"] += \"-\" + df.apply(lambda row: classify_progress(row[columns_to_compare[i]], row[columns_to_compare[i+1]]), axis=1)\n",
    "    \n",
    "    # Count occurrences per group\n",
    "    group_summary = df.groupby(\"group_class\")[\"progress\"].apply(lambda x: x.str.split(\"-\").explode().value_counts()).unstack().fillna(0)\n",
    "    \n",
    "    # Calculate percentage improvements\n",
    "    group_summary[\"Total\"] = group_summary.sum(axis=1)\n",
    "    group_summary[\"IMPROVEMENT_RATE\"] = group_summary[\"IMPROVED\"] / group_summary[\"Total\"]\n",
    "    \n",
    "    return group_summary\n",
    "\n",
    "all_results = []\n",
    "\n",
    "for file in survey_files:\n",
    "    if os.path.exists(file):\n",
    "        data = np.load(file, allow_pickle=True)\n",
    "        df = pd.DataFrame(data[\"arr_0\"], columns=data[\"columns\"])\n",
    "        group_performance = analyze_group_performance(df)\n",
    "        group_performance[\"Dataset\"] = file\n",
    "        all_results.append(group_performance)\n",
    "\n",
    "# Combine results from all datasets\n",
    "final_results = pd.concat(all_results)\n",
    "\n",
    "# Display the final results\n",
    "target_columns = [\"IMPROVED\", \"DECLINED\", \"SAME\", \"IMPROVEMENT_RATE\", \"Dataset\"]\n",
    "final_results = final_results[target_columns]\n",
    "import ace_tools as tools\n",
    "tools.display_dataframe_to_user(name=\"Group Performance Comparison\", dataframe=final_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87d3a9c-fa50-4dba-a9c5-9a1970c1d44d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
