{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemmatization   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I had an issue with NLTK\n",
    "# that is I opted for spacy\n",
    "import spacy\n",
    "import subprocess\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to download the spaCy model if not already installed\n",
    "def download_spacy_model():\n",
    "    try:\n",
    "        spacy.load(\"en_core_web_sm\")\n",
    "    except OSError:\n",
    "        print(\"Downloading 'en_core_web_sm' model...\")\n",
    "        subprocess.run([\"python\", \"-m\", \"spacy\", \"download\", \"en_core_web_sm\"], check=True)\n",
    "        print(\"Download complete!\")\n",
    "\n",
    "# Ensure the spaCy model is available\n",
    "download_spacy_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_text(text):\n",
    "    \"\"\"\n",
    "    Function to lemmatize text using spaCy.\n",
    "    :param text: str, input text\n",
    "    :return: str, lemmatized text\n",
    "    \"\"\"\n",
    "    if pd.isna(text):  # Handle NaN values\n",
    "        return \"\"\n",
    "\n",
    "    doc = nlp(text)  # Process the text using spaCy\n",
    "    return \" \".join([token.lemma_ for token in doc])  # Apply lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "file_path = \"processed_dataset.csv\"  # Replace with your actual dataset file path\n",
    "text_columns = [\"tableau_usage_pre\", \"api_usage_pre\", \"ml_application_pre\",\n",
    "                    \"persona_explanation_pre\", \"api_usage_pre\", \"ml_application_pre\",\n",
    "                    \"data_collection_explanation_post\", \"data_analysis_explanation_post\", \"persona_building_explanation_post\",\n",
    "                    \"evaluation_explanation_post\", \"tools_usage_post\", \"api_usage_post\",\n",
    "                    \"ml_application_post\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully!\n",
      "Processed dataset saved as processed_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    df = pd.read_csv(file_path)  # Load CSV file\n",
    "    print(\"Dataset loaded successfully!\")\n",
    "\n",
    "    # Apply lemmatization to each text column\n",
    "    for col in text_columns:\n",
    "        if col in df.columns:  # Ensure column exists before processing\n",
    "            df[col] = df[col].astype(str).apply(lemmatize_text)\n",
    "\n",
    "    # Save the processed dataset\n",
    "    output_file = \"processed_dataset.csv\"\n",
    "    df.to_csv(output_file, index=False)\n",
    "    print(f\"Processed dataset saved as {output_file}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error loading dataset: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_date_pre</th>\n",
       "      <th>end_date_pre</th>\n",
       "      <th>ip_address_pre</th>\n",
       "      <th>duration_sec_pre</th>\n",
       "      <th>response_id_pre</th>\n",
       "      <th>LocationLatitude_pre</th>\n",
       "      <th>LocationLongitude_pre</th>\n",
       "      <th>DistributionChannel_pre</th>\n",
       "      <th>UserLanguage_pre</th>\n",
       "      <th>participant_id</th>\n",
       "      <th>age_pre</th>\n",
       "      <th>gender_pre</th>\n",
       "      <th>occupation_pre</th>\n",
       "      <th>teaching_marketing_pre</th>\n",
       "      <th>teaching_experience_pre</th>\n",
       "      <th>learning_style_pre</th>\n",
       "      <th>learning_format_pre</th>\n",
       "      <th>interaction_preference_pre</th>\n",
       "      <th>trusted_learning_method_pre</th>\n",
       "      <th>ai_familiarity_pre</th>\n",
       "      <th>ddp_familiarity_pre</th>\n",
       "      <th>data_sources_pre</th>\n",
       "      <th>persona_definition_pre</th>\n",
       "      <th>interactive_persona_pre</th>\n",
       "      <th>data_driven_persona_pre</th>\n",
       "      <th>dynamic_persona_pre</th>\n",
       "      <th>tableau_usage_pre</th>\n",
       "      <th>api_usage_pre</th>\n",
       "      <th>ml_application_pre</th>\n",
       "      <th>persona_explanation_pre</th>\n",
       "      <th>confirmation_pre</th>\n",
       "      <th>start_date_post</th>\n",
       "      <th>end_date_post</th>\n",
       "      <th>ip_address_post</th>\n",
       "      <th>duration_sec_post</th>\n",
       "      <th>response_id_post</th>\n",
       "      <th>LocationLatitude_post</th>\n",
       "      <th>LocationLongitude_post</th>\n",
       "      <th>DistributionChannel_post</th>\n",
       "      <th>UserLanguage_post</th>\n",
       "      <th>data_collection_explanation_post</th>\n",
       "      <th>data_analysis_explanation_post</th>\n",
       "      <th>persona_building_explanation_post</th>\n",
       "      <th>evaluation_explanation_post</th>\n",
       "      <th>ai_familiarity_post</th>\n",
       "      <th>ddp_familiarity_post</th>\n",
       "      <th>data_sources_post</th>\n",
       "      <th>persona_definition_post</th>\n",
       "      <th>interactive_persona_post</th>\n",
       "      <th>data_driven_persona_post</th>\n",
       "      <th>dynamic_persona_post</th>\n",
       "      <th>tools_usage_post</th>\n",
       "      <th>api_usage_post</th>\n",
       "      <th>ml_application_post</th>\n",
       "      <th>engagement_experience_post</th>\n",
       "      <th>interaction_quality_post</th>\n",
       "      <th>communication_clarity_post</th>\n",
       "      <th>trustworthiness_post</th>\n",
       "      <th>emotional_response_post</th>\n",
       "      <th>naturalness_post</th>\n",
       "      <th>effectiveness_post</th>\n",
       "      <th>comfort_level_post</th>\n",
       "      <th>personalization_post</th>\n",
       "      <th>mental_effort_post</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2/13/25 0:10</td>\n",
       "      <td>2/13/25 0:16</td>\n",
       "      <td>193.166.113.18</td>\n",
       "      <td>372</td>\n",
       "      <td>R_8GBoA0i1k6yogS1</td>\n",
       "      <td>63.1198</td>\n",
       "      <td>21.6798</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>3,4</td>\n",
       "      <td>3,4</td>\n",
       "      <td>2,3,4</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>know</td>\n",
       "      <td>know</td>\n",
       "      <td>know</td>\n",
       "      <td>know</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-02-13 0:56:11</td>\n",
       "      <td>2025-02-13 1:18:59</td>\n",
       "      <td>193.166.113.18</td>\n",
       "      <td>1368</td>\n",
       "      <td>R_8QL21bpDcdbdtJ4</td>\n",
       "      <td>63.1198</td>\n",
       "      <td>21.6798</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>collect studen ' demographic datum , datum stu...</td>\n",
       "      <td>datum clean . achieve high quality datum . pri...</td>\n",
       "      <td>cluster combining , personas summarize order p...</td>\n",
       "      <td>evaluation e.g. , traditional / b testing meth...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>All of the above</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>communicate personas user . visualize personas...</td>\n",
       "      <td>relevant datum obtain .</td>\n",
       "      <td>e.g. , cluster combine datum .</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2/13/25 0:09</td>\n",
       "      <td>2/13/25 0:16</td>\n",
       "      <td>193.166.113.32</td>\n",
       "      <td>409</td>\n",
       "      <td>R_8QG2UV0Zv0fKVB5</td>\n",
       "      <td>63.1198</td>\n",
       "      <td>21.6798</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1,3,4</td>\n",
       "      <td>2,4</td>\n",
       "      <td>3,4</td>\n",
       "      <td>2,3,4</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>know tool , answer .</td>\n",
       "      <td>clue .</td>\n",
       "      <td>clue .</td>\n",
       "      <td>clue .</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-02-13 0:56:02</td>\n",
       "      <td>2025-02-13 1:13:21</td>\n",
       "      <td>193.166.113.32</td>\n",
       "      <td>1039</td>\n",
       "      <td>R_8QrAaCxxXwbpxvL</td>\n",
       "      <td>63.1198</td>\n",
       "      <td>21.6798</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>user analytic : Google analytic , CRM , api etc .</td>\n",
       "      <td>segmentation perform persona reflect certain b...</td>\n",
       "      <td>way create student persona identify possible s...</td>\n",
       "      <td>1 ) teach marketing course . \\n  2 ) participa...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>All of the above</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>illustrate ( update ) static persona profile .</td>\n",
       "      <td>clue API .</td>\n",
       "      <td>create dynamic persona .</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2/13/25 0:09</td>\n",
       "      <td>2/13/25 0:17</td>\n",
       "      <td>193.166.113.31</td>\n",
       "      <td>462</td>\n",
       "      <td>R_8tHW5RDZd4yBkcx</td>\n",
       "      <td>63.1198</td>\n",
       "      <td>21.6798</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1,3</td>\n",
       "      <td>3,4</td>\n",
       "      <td>3,4</td>\n",
       "      <td>2,3,4</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>1,3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>know .</td>\n",
       "      <td>know API stand .</td>\n",
       "      <td>know .</td>\n",
       "      <td>know .</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-02-13 10:06:34</td>\n",
       "      <td>2025-02-13 10:19:38</td>\n",
       "      <td>193.166.113.31</td>\n",
       "      <td>784</td>\n",
       "      <td>R_2kRKZFGiWHUQidw</td>\n",
       "      <td>63.1198</td>\n",
       "      <td>21.6798</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>need quantitative datum , obtain survey , onli...</td>\n",
       "      <td>statistical analysis require . include cluster...</td>\n",
       "      <td>stage , craft persona profile comes play . dis...</td>\n",
       "      <td>crucial step persona building validate persona...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>All of the above</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>visualise persona .</td>\n",
       "      <td>not know api stand .</td>\n",
       "      <td>know .</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2/13/25 0:11</td>\n",
       "      <td>2/13/25 0:17</td>\n",
       "      <td>193.166.113.21</td>\n",
       "      <td>355</td>\n",
       "      <td>R_8462bTis2cTNcii</td>\n",
       "      <td>63.1198</td>\n",
       "      <td>21.6798</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1,2,3,4</td>\n",
       "      <td>3,4</td>\n",
       "      <td>3,4</td>\n",
       "      <td>2,3,4</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-02-13 0:55:51</td>\n",
       "      <td>2025-02-13 1:11:01</td>\n",
       "      <td>193.166.113.21</td>\n",
       "      <td>909</td>\n",
       "      <td>R_2M3diy3SR17ual3</td>\n",
       "      <td>63.1198</td>\n",
       "      <td>21.6798</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>datum source : Attendance , group task evaluat...</td>\n",
       "      <td>clustering , matrix pattern , AI software clus...</td>\n",
       "      <td>use datum build representative personas catego...</td>\n",
       "      <td>test exist network persona represent certain p...</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>All of the above</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>datum analysis</td>\n",
       "      <td>collect datum</td>\n",
       "      <td>great deal . help process large datum ro creat...</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2/13/25 0:09</td>\n",
       "      <td>2/13/25 0:18</td>\n",
       "      <td>193.166.117.7</td>\n",
       "      <td>551</td>\n",
       "      <td>R_824J8ZB9ZGfOu8t</td>\n",
       "      <td>63.1198</td>\n",
       "      <td>21.6798</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>38</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1,2,4</td>\n",
       "      <td>4</td>\n",
       "      <td>3,4</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-02-13 0:55:35</td>\n",
       "      <td>2025-02-13 1:19:16</td>\n",
       "      <td>193.166.117.7</td>\n",
       "      <td>1421</td>\n",
       "      <td>R_2KPeTVjwHtRdvU7</td>\n",
       "      <td>63.1198</td>\n",
       "      <td>21.6798</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-age , job , demographic datum , behave intera...</td>\n",
       "      <td>-clustere student accord goal , challenge , sh...</td>\n",
       "      <td>-making descriptive profile poster persona sha...</td>\n",
       "      <td>-personas static update regularly new trend in...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>All of the above</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>poster persona access datum ( communicate pers...</td>\n",
       "      <td>analysis ? know API .</td>\n",
       "      <td>develop personas new information available ? e...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  start_date_pre  end_date_pre  ip_address_pre  duration_sec_pre  \\\n",
       "0   2/13/25 0:10  2/13/25 0:16  193.166.113.18               372   \n",
       "1   2/13/25 0:09  2/13/25 0:16  193.166.113.32               409   \n",
       "2   2/13/25 0:09  2/13/25 0:17  193.166.113.31               462   \n",
       "3   2/13/25 0:11  2/13/25 0:17  193.166.113.21               355   \n",
       "4   2/13/25 0:09  2/13/25 0:18   193.166.117.7               551   \n",
       "\n",
       "     response_id_pre  LocationLatitude_pre  LocationLongitude_pre  \\\n",
       "0  R_8GBoA0i1k6yogS1               63.1198                21.6798   \n",
       "1  R_8QG2UV0Zv0fKVB5               63.1198                21.6798   \n",
       "2  R_8tHW5RDZd4yBkcx               63.1198                21.6798   \n",
       "3  R_8462bTis2cTNcii               63.1198                21.6798   \n",
       "4  R_824J8ZB9ZGfOu8t               63.1198                21.6798   \n",
       "\n",
       "   DistributionChannel_pre  UserLanguage_pre  participant_id  age_pre  \\\n",
       "0                        0                 0               1       60   \n",
       "1                        0                 0              23       41   \n",
       "2                        0                 0              22       45   \n",
       "3                        0                 0              19       39   \n",
       "4                        0                 0              15       38   \n",
       "\n",
       "   gender_pre  occupation_pre  teaching_marketing_pre teaching_experience_pre  \\\n",
       "0           1               1                       1                      20   \n",
       "1           1               2                       2                       0   \n",
       "2           1               2                       1                       3   \n",
       "3           1               2                       1                       1   \n",
       "4           2               2                       2                       0   \n",
       "\n",
       "  learning_style_pre learning_format_pre interaction_preference_pre  \\\n",
       "0                  3                 3,4                        3,4   \n",
       "1              1,3,4                 2,4                        3,4   \n",
       "2                1,3                 3,4                        3,4   \n",
       "3            1,2,3,4                 3,4                        3,4   \n",
       "4              1,2,4                   4                        3,4   \n",
       "\n",
       "  trusted_learning_method_pre  ai_familiarity_pre  ddp_familiarity_pre  \\\n",
       "0                       2,3,4                  12                   10   \n",
       "1                       2,3,4                  10                    1   \n",
       "2                       2,3,4                  11                   10   \n",
       "3                       2,3,4                  12                    1   \n",
       "4                           2                  12                    1   \n",
       "\n",
       "  data_sources_pre  persona_definition_pre  interactive_persona_pre  \\\n",
       "0                4                       1                        2   \n",
       "1                4                       1                        2   \n",
       "2              1,3                       1                        5   \n",
       "3                4                       1                        5   \n",
       "4                5                       5                        5   \n",
       "\n",
       "   data_driven_persona_pre  dynamic_persona_pre     tableau_usage_pre  \\\n",
       "0                        2                    1                  know   \n",
       "1                        2                    1  know tool , answer .   \n",
       "2                        2                    5                know .   \n",
       "3                        2                    5                   nan   \n",
       "4                        5                    5                     -   \n",
       "\n",
       "      api_usage_pre ml_application_pre persona_explanation_pre  \\\n",
       "0              know               know                    know   \n",
       "1            clue .             clue .                  clue .   \n",
       "2  know API stand .             know .                  know .   \n",
       "3               nan                nan                     nan   \n",
       "4                 -                  -                       -   \n",
       "\n",
       "   confirmation_pre      start_date_post        end_date_post ip_address_post  \\\n",
       "0                 0   2025-02-13 0:56:11   2025-02-13 1:18:59  193.166.113.18   \n",
       "1                 0   2025-02-13 0:56:02   2025-02-13 1:13:21  193.166.113.32   \n",
       "2                 0  2025-02-13 10:06:34  2025-02-13 10:19:38  193.166.113.31   \n",
       "3                 0   2025-02-13 0:55:51   2025-02-13 1:11:01  193.166.113.21   \n",
       "4                 0   2025-02-13 0:55:35   2025-02-13 1:19:16   193.166.117.7   \n",
       "\n",
       "   duration_sec_post   response_id_post  LocationLatitude_post  \\\n",
       "0               1368  R_8QL21bpDcdbdtJ4                63.1198   \n",
       "1               1039  R_8QrAaCxxXwbpxvL                63.1198   \n",
       "2                784  R_2kRKZFGiWHUQidw                63.1198   \n",
       "3                909  R_2M3diy3SR17ual3                63.1198   \n",
       "4               1421  R_2KPeTVjwHtRdvU7                63.1198   \n",
       "\n",
       "   LocationLongitude_post  DistributionChannel_post  UserLanguage_post  \\\n",
       "0                 21.6798                         0                  0   \n",
       "1                 21.6798                         0                  0   \n",
       "2                 21.6798                         0                  0   \n",
       "3                 21.6798                         0                  0   \n",
       "4                 21.6798                         0                  0   \n",
       "\n",
       "                    data_collection_explanation_post  \\\n",
       "0  collect studen ' demographic datum , datum stu...   \n",
       "1  user analytic : Google analytic , CRM , api etc .   \n",
       "2  need quantitative datum , obtain survey , onli...   \n",
       "3  datum source : Attendance , group task evaluat...   \n",
       "4  -age , job , demographic datum , behave intera...   \n",
       "\n",
       "                      data_analysis_explanation_post  \\\n",
       "0  datum clean . achieve high quality datum . pri...   \n",
       "1  segmentation perform persona reflect certain b...   \n",
       "2  statistical analysis require . include cluster...   \n",
       "3  clustering , matrix pattern , AI software clus...   \n",
       "4  -clustere student accord goal , challenge , sh...   \n",
       "\n",
       "                   persona_building_explanation_post  \\\n",
       "0  cluster combining , personas summarize order p...   \n",
       "1  way create student persona identify possible s...   \n",
       "2  stage , craft persona profile comes play . dis...   \n",
       "3  use datum build representative personas catego...   \n",
       "4  -making descriptive profile poster persona sha...   \n",
       "\n",
       "                         evaluation_explanation_post  ai_familiarity_post  \\\n",
       "0  evaluation e.g. , traditional / b testing meth...                    4   \n",
       "1  1 ) teach marketing course . \\n  2 ) participa...                    2   \n",
       "2  crucial step persona building validate persona...                    3   \n",
       "3  test exist network persona represent certain p...                    4   \n",
       "4  -personas static update regularly new trend in...                    4   \n",
       "\n",
       "   ddp_familiarity_post data_sources_post  persona_definition_post  \\\n",
       "0                     4  All of the above                        0   \n",
       "1                     2  All of the above                        0   \n",
       "2                     4  All of the above                        0   \n",
       "3                     5  All of the above                        0   \n",
       "4                     2  All of the above                        0   \n",
       "\n",
       "   interactive_persona_post  data_driven_persona_post  dynamic_persona_post  \\\n",
       "0                         1                         0                     0   \n",
       "1                         1                         0                     0   \n",
       "2                         2                         0                     1   \n",
       "3                         1                         0                     0   \n",
       "4                         1                         0                     0   \n",
       "\n",
       "                                    tools_usage_post           api_usage_post  \\\n",
       "0  communicate personas user . visualize personas...  relevant datum obtain .   \n",
       "1     illustrate ( update ) static persona profile .               clue API .   \n",
       "2                                visualise persona .     not know api stand .   \n",
       "3                                     datum analysis            collect datum   \n",
       "4  poster persona access datum ( communicate pers...    analysis ? know API .   \n",
       "\n",
       "                                 ml_application_post  \\\n",
       "0                     e.g. , cluster combine datum .   \n",
       "1                           create dynamic persona .   \n",
       "2                                             know .   \n",
       "3  great deal . help process large datum ro creat...   \n",
       "4  develop personas new information available ? e...   \n",
       "\n",
       "   engagement_experience_post  interaction_quality_post  \\\n",
       "0                           5                         1   \n",
       "1                           4                         2   \n",
       "2                           3                         4   \n",
       "3                           6                         6   \n",
       "4                           4                         2   \n",
       "\n",
       "   communication_clarity_post  trustworthiness_post  emotional_response_post  \\\n",
       "0                           7                     2                        2   \n",
       "1                           4                     4                        2   \n",
       "2                           6                     6                        1   \n",
       "3                           6                     4                        2   \n",
       "4                           3                     3                        1   \n",
       "\n",
       "   naturalness_post  effectiveness_post  comfort_level_post  \\\n",
       "0                 1                   6                   6   \n",
       "1                 4                   4                   2   \n",
       "2                 4                   5                   3   \n",
       "3                 3                   6                   1   \n",
       "4                 4                   3                   6   \n",
       "\n",
       "   personalization_post  mental_effort_post  \n",
       "0                     1                   4  \n",
       "1                     2                   6  \n",
       "2                     4                   5  \n",
       "3                     4                   4  \n",
       "4                     1                   6  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the cleaned dataset\n",
    "# Ensure all columns are displayed\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
