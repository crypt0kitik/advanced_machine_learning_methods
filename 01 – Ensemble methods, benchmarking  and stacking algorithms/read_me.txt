There 2 datasets. Both of them were used in the previous projects that is why they are cleaned and numeric. In other words, they were ready to be used.

Classifiaction dataset:
01 - Logistic Regression
01.2 - Logistic Regression. Scaling
02 - XGBoost
03 - CatBoost - the best
03.2 - CatBoost. Upgraded (after developing all models, I saw that CatBoost had the best results. I decided to improve the model to see if I can make it even better)
04 - AdaBoost
05 - LightGBM
06 - Random Forest
07 - KNN (K-Nearest Neighbors)
07.2 - KNN. Upgraded
08 - SVM (Support Vector Machine) - it took too long to train the model (more than 26 mins)
09 - Ridge Classifier
10 - Stacking Classifier - 2nd place


Regression dataset:
01 - Logistic Regression
02 - XGBoost
03 - CatBoost 
04 - AdaBoost
05 - LightGBM
06 - Random Forest
07 - KNN (K-Nearest Neighbors)
08 - SVM (Support Vector Machine) - it took too long to train the model (more than 25 mins), that is why I ommited this algorithm
09 - Ridge (Lasso) Regression
10 - Stacking Classifier

Note: experimenting with all these models, I was constantly worried about RÂ² Score. It did not show better results than 0.5. All other metrics were more or less good.